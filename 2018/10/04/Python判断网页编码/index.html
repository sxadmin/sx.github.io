<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python判断网页编码 | Sxadmin blog</title><meta name="description" content="做爬虫或者测试的时候，返回网页的编码是个很让人头疼的问题，这篇文章做个网页编码问题解决方法总结。"><meta name="keywords" content="Python爬虫,编码"><meta name="author" content="Sxadmin"><meta name="copyright" content="Sxadmin"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://s1.ax1x.com/2020/06/15/NpA1v6.th.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Python判断网页编码"><meta name="twitter:description" content="做爬虫或者测试的时候，返回网页的编码是个很让人头疼的问题，这篇文章做个网页编码问题解决方法总结。"><meta name="twitter:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><meta property="og:type" content="article"><meta property="og:title" content="Python判断网页编码"><meta property="og:url" content="https://sxadmin.github.io/2018/10/04/Python%E5%88%A4%E6%96%AD%E7%BD%91%E9%A1%B5%E7%BC%96%E7%A0%81/"><meta property="og:site_name" content="Sxadmin blog"><meta property="og:description" content="做爬虫或者测试的时候，返回网页的编码是个很让人头疼的问题，这篇文章做个网页编码问题解决方法总结。"><meta property="og:image" content="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><meta property="article:published_time" content="2018-10-04T09:37:58.000Z"><meta property="article:modified_time" content="2020-06-15T03:37:29.600Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://sxadmin.github.io/2018/10/04/Python%E5%88%A4%E6%96%AD%E7%BD%91%E9%A1%B5%E7%BC%96%E7%A0%81/"><link rel="prev" title="Python字符集编码" href="https://sxadmin.github.io/2018/10/14/Python%E5%AD%97%E7%AC%A6%E9%9B%86%E7%BC%96%E7%A0%81/"><link rel="next" title="Python可视化初探-py2" href="https://sxadmin.github.io/2018/08/26/Python%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%9D%E6%8E%A2/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='https://s1.ax1x.com/2020/06/15/NpPYfx.jpg'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">87</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">60</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">10</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 時間軸</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 關於</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#根据网页返回编码寻找数据"><span class="toc-number">1.</span> <span class="toc-text">根据网页返回编码寻找数据</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#使用chardet直接判断转换"><span class="toc-number">2.</span> <span class="toc-text">使用chardet直接判断转换</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#当然更简单的方式"><span class="toc-number">3.</span> <span class="toc-text">当然更简单的方式</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#获取网页信息"><span class="toc-number">4.</span> <span class="toc-text">获取网页信息</span></a></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Sxadmin blog</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 時間軸</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 關於</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Python判断网页编码</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2018-10-04 17:37:58"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2018-10-04</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-06-15 11:37:29"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-06-15</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0/">爬虫笔记</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><blockquote class="blockquote-center">有一种渴，只有酒才能滋润，这种渴就是孤独。</blockquote>

<script type="text/javascript" src="/js/src/bai.js"></script>

<h1 id="根据网页返回编码寻找数据"><a href="#根据网页返回编码寻找数据" class="headerlink" title="根据网页返回编码寻找数据"></a>根据网页返回编码寻找数据</h1><p>比如我要找到这个网页的标题，那么直接正则匹配<title>(.*?)</title>就可以，但是许多时候因为编码问题requests这个库没办法正确解析，所以获取不到数据。</p>
<p>解决办法：</p>
<pre><code>r_port_top = requests.get(url=str(&apos;http://&apos;+url), headers=headers, timeout=5)
if r_port_top.encoding == &apos;ISO-8859-1&apos;:
    encodings = requests.utils.get_encodings_from_content(r_port_top.text)
    if encodings:
        encoding = encodings[0]
    else:
        encoding = r_port_top.apparent_encoding
    encode_content = r_port_top.content.decode(encoding, &apos;replace&apos;).encode(&apos;utf-8&apos;, &apos;replace&apos;)
    port_title = re.search(&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos;, encode_content, re.S).group().replace(&apos;&lt;title&gt;&apos;,
                                                                                         &apos;&apos;).replace(
        &apos;&lt;/title&gt;&apos;, &apos;&apos;)</code></pre><p>这种办法就是先判断网页的编码，然后转换之。但是有的时候是utf-8编码就没办法，接下来来个终极版的。</p>
<pre><code>try:
    UA = random.choice(headerss)
    headers = {&apos;User-Agent&apos;: UA}
    r_port_top = requests.get(url=str(&apos;http://&apos;+url), headers=headers, timeout=5)
    if r_port_top.encoding == &apos;ISO-8859-1&apos;:
        encodings = requests.utils.get_encodings_from_content(r_port_top.text)
        if encodings:
            encoding = encodings[0]
        else:
            encoding = r_port_top.apparent_encoding
        encode_content = r_port_top.content.decode(encoding, &apos;replace&apos;).encode(&apos;utf-8&apos;, &apos;replace&apos;)
        port_title = re.search(&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos;, encode_content, re.S).group().replace(&apos;&lt;title&gt;&apos;,
                                                                                             &apos;&apos;).replace(
            &apos;&lt;/title&gt;&apos;, &apos;&apos;)
    elif r_port_top.encoding == &apos;GB2312&apos;:
        encodings = requests.utils.get_encodings_from_content(r_port_top.text)
        if encodings:
            encoding = encodings[0]
        else:
            encoding = r_port_top.apparent_encoding
        encode_content = r_port_top.content.decode(encoding, &apos;replace&apos;).encode(&apos;utf-8&apos;, &apos;replace&apos;)
        port_title = re.search(&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos;, encode_content, re.S).group().replace(&apos;&lt;title&gt;&apos;,
                                                                                             &apos;&apos;).replace(
            &apos;&lt;/title&gt;&apos;, &apos;&apos;)
    elif r_port_top.encoding == &apos;gb2312&apos;:
        encodings = requests.utils.get_encodings_from_content(r_port_top.text)
        if encodings:
            encoding = encodings[0]
        else:
            encoding = r_port_top.apparent_encoding
        encode_content = r_port_top.content.decode(encoding, &apos;replace&apos;).encode(&apos;utf-8&apos;, &apos;replace&apos;)
        port_title = re.search(&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos;, encode_content, re.S).group().replace(&apos;&lt;title&gt;&apos;,
                                                                                             &apos;&apos;).replace(
            &apos;&lt;/title&gt;&apos;, &apos;&apos;)
    elif r_port_top.encoding == &apos;GBK&apos;:
        encodings = requests.utils.get_encodings_from_content(r_port_top.text)
        if encodings:
            encoding = encodings[0]
        else:
            encoding = r_port_top.apparent_encoding
        encode_content = r_port_top.content.decode(encoding, &apos;replace&apos;).encode(&apos;utf-8&apos;, &apos;replace&apos;)
        port_title = re.search(&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos;, encode_content, re.S).group().replace(&apos;&lt;title&gt;&apos;,
                                                                                             &apos;&apos;).replace(
            &apos;&lt;/title&gt;&apos;, &apos;&apos;)
    elif r_port_top.encoding == &apos;gbk&apos;:
        encodings = requests.utils.get_encodings_from_content(r_port_top.text)
        if encodings:
            encoding = encodings[0]
        else:
            encoding = r_port_top.apparent_encoding
        encode_content = r_port_top.content.decode(encoding, &apos;replace&apos;).encode(&apos;utf-8&apos;, &apos;replace&apos;)
        port_title = re.search(&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos;, encode_content, re.S).group().replace(&apos;&lt;title&gt;&apos;,
                                                                                             &apos;&apos;).replace(
            &apos;&lt;/title&gt;&apos;, &apos;&apos;)
    else:
        port_title = re.search(&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos;, r_port_top.content, re.S).group().replace(&apos;&lt;title&gt;&apos;,
                                                                                                 &apos;&apos;).replace(
            &apos;&lt;/title&gt;&apos;, &apos;&apos;)
except:
    try:
        port_title = re.search(&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos;, r_port_top.content, re.S).group().replace(&apos;&lt;title&gt;&apos;,
                                                                                                 &apos;&apos;).replace(
            &apos;&lt;/title&gt;&apos;, &apos;&apos;)
    except:
        port_title = &apos;暂时无法获取网站标题&apos;</code></pre><h1 id="使用chardet直接判断转换"><a href="#使用chardet直接判断转换" class="headerlink" title="使用chardet直接判断转换"></a>使用chardet直接判断转换</h1><p>上面那个方法实在是太傻了，使用chardet轻松解决网页编码问题。</p>
<pre><code># -*- coding: utf-8 -*-
# @Time    : 2018/5/4 0004 8:55
# @Author  : Langzi
# @Blog    : www.sxadmin.github.io
# @File    : get urls.py
# @Software: PyCharm
import sys
import chardet
import re
import requests

reload(sys)
sys.setdefaultencoding(&apos;utf-8&apos;)

url = &apos;https://stackoverflow.com&apos;
d1 = requests.get(url)
print d1.content
if isinstance(d1.content,unicode):
    pass
else:
    codesty = chardet.detect(d1.content)
    a = d1.content.decode(codesty[&apos;encoding&apos;])</code></pre><p>得到的a就是网页最终编码后的结果，这个时候直接re.search(‘<title>(.*?)</title>‘,a)就可以达到了匹配所有网址的标题了。</p>
<h1 id="当然更简单的方式"><a href="#当然更简单的方式" class="headerlink" title="当然更简单的方式"></a>当然更简单的方式</h1><p>requests自带的一个api可以快速识别网页编码，然后转换成utf-8编码</p>
<pre><code>import requests
url = &apos;https://sxadmin.github.io&apos;
r = requests.get(url)
encoing = requests.utils.get_encodings_from_content(r.text)[0]
print(encoing)
res = r.content.decode(encoing,&apos;replace&apos;)
#  替换其中异常的编码，这个相对来可能一眼就知道那些字符编码出问题了。
res = r.content.decode(encoing,&apos;ignore&apos;)
# 忽略其中有异常的编码，仅显示有效的编码</code></pre><p>通过查看该api的源码，得知它实现的原理是用正则表达式获取到网页中的编码</p>
<pre><code>def get_encodings_from_content(content):
    charset_re = re.compile(r&apos;&lt;meta.*?charset=[&quot;\&apos;]*(.+?)[&quot;\&apos;&gt;]&apos;, flags=re.I)
    pragma_re = re.compile(r&apos;&lt;meta.*?content=[&quot;\&apos;]*;?charset=(.+?)[&quot;\&apos;&gt;]&apos;, flags=re.I)
    xml_re = re.compile(r&apos;^&lt;\?xml.*?encoding=[&quot;\&apos;]*(.+?)[&quot;\&apos;&gt;]&apos;)

    return (charset_re.findall(content) +
            pragma_re.findall(content) +
            xml_re.findall(content))</code></pre><p>知道原理后，就可以把这个函数拿来移植到自己的功能函数中，也是学到了噢~</p>
<h1 id="获取网页信息"><a href="#获取网页信息" class="headerlink" title="获取网页信息"></a>获取网页信息</h1><p>使用chardet库来进行编码判断</p>
<p>如果想要获取网页的标题和内容以及网页中的外链，写了一个类来实现。使用方法如下</p>
<pre><code>d = Get_Info(url=&apos;https://sxadmin.github.io&apos;)
d1 = d.get_urls()
# 返回这个传入网址中所有的外链，返回对象为列表，如果没有数据返回None，下同
d2 = d.get_infos()
# 返回这个网址中的标题，内容，返回对象为字典
d3 = d.get_ips()
# 返回这个网址的ip和开放端口，返回对象为字典</code></pre><p>具体代码如下：</p>
<pre><code># coding:utf-8

import re
import requests
import time
import socket
from bs4 import BeautifulSoup as bs
import chardet
import sys
reload(sys)
sys.setdefaultencoding(&apos;utf-8&apos;)
timeout = 3
socket.setdefaulttimeout(timeout)
from requests.packages import urllib3
urllib3.disable_warnings()
ports = [
    21,
    22,
    23,
    25,
    53,
    69,
    139,
    445,
    389,
    1433,
    1521,
    2181,
    3306,
    3389,
    5432,
    5984,
    6379,
    7001,
    7002,
    8069,
    11211,
    27017,
    27018,
    50070,
    50030
]


class Get_Info:
    def __init__(self,url):
        self.url = url


    def get_ips(self):
        url_port = []
        url_port.append(80)
        hostname = self.url.replace(&apos;http://&apos;,&apos;&apos;).replace(&apos;https://&apos;,&apos;&apos;).replace(&apos;/&apos;,&apos;&apos;)
        url_ip = &apos;None&apos;
        try:
            url_ip= socket.gethostbyname(str(hostname))
        except:
            pass
        if url_ip and url_ip!= &apos;None&apos;:
            for port in ports:
                s = socket.socket()
                try:
                    s.connect((url_ip,port))
                    url_port.append(port)
                except Exception,e:
                    # print e
                    pass
                finally:
                    s.close()
        if url_ip and url_ip != &apos;None&apos;:
            infos = {}
            infos[&apos;ip&apos;] = str(url_ip)
            infos[&apos;ports&apos;] = str(url_port)
            return infos
        else:
            return None

    def get_infos(self):
        try:
            headers = {&apos;User-Agent&apos;: &apos;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&apos;}
            r = requests.get(url=self.url,headers=headers,verify=False,timeout=5)
            url_title,url_content,url_service = &apos;获取失败&apos;,&apos;获取失败&apos;,&apos;获取失败&apos;
            try:
                code = chardet.detect(r.content)[&apos;encoding&apos;]
                bp = bs(r.content.decode(code).encode(&apos;utf-8&apos;),&apos;html.parser&apos;)
                url_title = bp.title.string
                url_content = bp.text
                url_service = r.headers
            except:
                url_title = re.search(&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos;,r.content,re.I).group(1).decode(code).encode(&apos;utf-8&apos;)
                url_content = re.sub(&apos;([\.\?\*~!@#{$%\^&amp;\*()-;&quot;&lt;&gt;\[\]}_\+=]|[0-9]|[a-z]|[A-Z])&apos;,&apos;&apos;,r.text)
                url_service = r.headers
            infos = {}
            infos[&apos;url&apos;] = r.url
            infos[&apos;title&apos;] = url_title
            url_contents = &apos;&apos;.join(r.text.split()).replace(&apos; &apos;,&apos;&apos;)
            infos[&apos;content&apos;] = re.sub(&apos;([\.\?\*~!@#{$%\^&amp;\*()-;&quot;&lt;&gt;\[\]}_\+=]|[0-9]|[a-z]|[A-Z])&apos;,&apos;&apos;,url_contents).replace(&apos;|&apos;,&apos;&apos;).replace(&quot;&apos;&quot;,&apos;&apos;)
            infos[&apos;service&apos;] = url_service
            if infos:
                return infos
            else:
                return None
        except Exception,e:
            print e


    def get_urls(self):
        urlss = []
        headers = {&apos;User-Agent&apos;: &apos;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&apos;}
        try:
            r = requests.get(url=self.url, headers=headers, verify=False, timeout=5)
            pattern = re.compile(r&apos;http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&amp;+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+&apos;,re.I)
            urls = re.findall(pattern,r.content)
            for x in urls:
                a1, a2 = x.split(&apos;//&apos;)[0], x.split(&apos;//&apos;)[1].split(&apos;/&apos;)[0]
                a3 = &apos;&apos;.join(a1) + &apos;//&apos; + &apos;&apos;.join(a2)
                urlss.append(a3.replace(&quot;&apos;&quot;,&quot;&quot;).replace(&apos;&gt;&apos;,&apos;&apos;).replace(&apos;&lt;&apos;,&apos;&apos;))
            if urlss:
                return list(set(urlss))
            else:
                return None
        except Exception,e:
            print e
            pass</code></pre></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Sxadmin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://sxadmin.github.io/2018/10/04/Python%E5%88%A4%E6%96%AD%E7%BD%91%E9%A1%B5%E7%BC%96%E7%A0%81/">https://sxadmin.github.io/2018/10/04/Python%E5%88%A4%E6%96%AD%E7%BD%91%E9%A1%B5%E7%BC%96%E7%A0%81/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://sxadmin.github.io" target="_blank">Sxadmin blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%9F%BA%E7%A1%80/">基础</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.jpg" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2018/10/14/Python%E5%AD%97%E7%AC%A6%E9%9B%86%E7%BC%96%E7%A0%81/"><img class="prev_cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python字符集编码</div></div></a></div><div class="next-post pull_right"><a href="/2018/08/26/Python%E5%8F%AF%E8%A7%86%E5%8C%96%E5%88%9D%E6%8E%A2/"><img class="next_cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Python可视化初探-py2</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2018/04/28/Python Queue 模块/" title="Python Queue 模块"><img class="relatedPosts_cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2018-04-28</div><div class="relatedPosts_title">Python Queue 模块</div></div></a></div><div class="relatedPosts_item"><a href="/2018/05/04/Python collections 模块/" title="Python collections 模块"><img class="relatedPosts_cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2018-05-04</div><div class="relatedPosts_title">Python collections 模块</div></div></a></div><div class="relatedPosts_item"><a href="/2018/04/28/Python getpass 模块/" title="Python getpass 模块"><img class="relatedPosts_cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2018-04-28</div><div class="relatedPosts_title">Python getpass 模块</div></div></a></div><div class="relatedPosts_item"><a href="/2018/04/27/Python hashlib 模块/" title="Python hashlib 模块"><img class="relatedPosts_cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2018-04-27</div><div class="relatedPosts_title">Python hashlib 模块</div></div></a></div><div class="relatedPosts_item"><a href="/2018/04/28/Python json 模块/" title="Python json 模块"><img class="relatedPosts_cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2018-04-28</div><div class="relatedPosts_title">Python json 模块</div></div></a></div><div class="relatedPosts_item"><a href="/2018/04/28/Python logging 模块/" title="Python logging 模块"><img class="relatedPosts_cover" src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2018-04-28</div><div class="relatedPosts_title">Python logging 模块</div></div></a></div></div><div class="clear_both"></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Sxadmin</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@3/instantpage.min.js" type="module"></script></body></html>
<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python multiprocess 多进程模块 | Sxadmin blog</title><meta name="description" content="Python多进程笔记，包括共享数据，进程锁，进程池的用法总结。"><meta name="keywords" content="多线程"><meta name="author" content="Sxadmin"><meta name="copyright" content="Sxadmin"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://s1.ax1x.com/2020/06/15/NpA1v6.th.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="dns-prefetch" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="dns-prefetch" href="https://fonts.googleapis.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="dns-prefetch" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Python multiprocess 多进程模块"><meta name="twitter:description" content="Python多进程笔记，包括共享数据，进程锁，进程池的用法总结。"><meta name="twitter:image" content="https://sxadmin.github.io/img/cover/cover11.png"><meta property="og:type" content="article"><meta property="og:title" content="Python multiprocess 多进程模块"><meta property="og:url" content="https://sxadmin.github.io/2018/04/30/Python%20multiprocess%20%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9D%97/"><meta property="og:site_name" content="Sxadmin blog"><meta property="og:description" content="Python多进程笔记，包括共享数据，进程锁，进程池的用法总结。"><meta property="og:image" content="https://sxadmin.github.io/img/cover/cover11.png"><meta property="article:published_time" content="2018-04-30T12:55:04.000Z"><meta property="article:modified_time" content="2019-09-17T03:38:09.000Z"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://sxadmin.github.io/2018/04/30/Python%20multiprocess%20%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9D%97/"><link rel="prev" title="Python collections 模块" href="https://sxadmin.github.io/2018/05/04/Python%20collections%20%E6%A8%A1%E5%9D%97/"><link rel="next" title="Python threading 多线程模块" href="https://sxadmin.github.io/2018/04/30/Python%20threading%20%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9D%97/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.1"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='https://s1.ax1x.com/2020/06/15/NpPYfx.jpg'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">92</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">64</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">12</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 時間軸</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 關於</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#案例一-基础用法"><span class="toc-number">1.</span> <span class="toc-text">案例一 基础用法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#案例二-数据通信"><span class="toc-number">2.</span> <span class="toc-text">案例二 数据通信</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#使用Array共享数据"><span class="toc-number">2.1.</span> <span class="toc-text">使用Array共享数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用Manager共享数据"><span class="toc-number">2.2.</span> <span class="toc-text">使用Manager共享数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用queues的Queue类共享数据"><span class="toc-number">2.3.</span> <span class="toc-text">使用queues的Queue类共享数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用pipe实现进程间通信"><span class="toc-number">2.4.</span> <span class="toc-text">使用pipe实现进程间通信</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#案例三-进程锁"><span class="toc-number">3.</span> <span class="toc-text">案例三 进程锁</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#案例四-进程池"><span class="toc-number">4.</span> <span class="toc-text">案例四 进程池</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#案例五-爬虫进程池"><span class="toc-number">5.</span> <span class="toc-text">案例五 爬虫进程池</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#什么是分布式爬虫"><span class="toc-number">5.1.</span> <span class="toc-text">什么是分布式爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#我们的分布式爬虫"><span class="toc-number">5.2.</span> <span class="toc-text">我们的分布式爬虫</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#测试普通爬法"><span class="toc-number">5.3.</span> <span class="toc-text">测试普通爬法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#测试分布式爬法"><span class="toc-number">5.4.</span> <span class="toc-text">测试分布式爬法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#各模块作用"><span class="toc-number">6.</span> <span class="toc-text">各模块作用</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Process介绍"><span class="toc-number">6.1.</span> <span class="toc-text">Process介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pool介绍"><span class="toc-number">6.2.</span> <span class="toc-text">Pool介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#子进程返回值"><span class="toc-number">6.3.</span> <span class="toc-text">子进程返回值</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(/img/cover/cover11.png)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">Sxadmin blog</a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首頁</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 時間軸</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 標籤</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分類</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友鏈</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 關於</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">Python multiprocess 多进程模块</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2018-04-30 20:55:04"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2018-04-30</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2019-09-17 11:38:09"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2019-09-17</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Python%E8%BF%9B%E9%98%B6%E7%AC%94%E8%AE%B0/">Python进阶笔记</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><blockquote class="blockquote-center">如果一个人心里藏了那么多的喜怒哀乐，一定曾经活得伤痕累累。</blockquote>

<script type="text/javascript" src="/js/src/bai.js"></script>

<p>需要注意的是，如果使用多线程，用法一定要加上if <strong>name</strong> == <strong>main</strong>(Python中的multiprocess提供了Process类，实现进程相关的功能。但是它基于fork机制，因此不被windows平台支持。想要在windows中运行，必须使用if <strong>name</strong> == ‘<strong>main</strong>:的方式)，但是我有另一种方法在使用线程池的时候可以不使用name_mian，最下面说。</p>
<p>并且多线程就是开启多个线程，每个线程之间是不会互相通信互相干扰的，适用于密集计算。</p>
<h1 id="案例一-基础用法"><a href="#案例一-基础用法" class="headerlink" title="案例一 基础用法"></a>案例一 基础用法</h1><p>多进程的使用方法和多线程使用方法基本一样，所以如果你会多线程用法多进程也就懂了，有一点要注意，定义多进程，然后传递参数的时候，如果是有一个参数就是用args=（i，）一定要加上逗号，如果有两个或者以上的参数就不用这样。</p>
<pre><code>import sys
import multiprocessing
reload(sys)
sys.setdefaultencoding(&apos;utf-8&apos;)
def fun(i):
    print sys.path
    print sys.version_info
    print sys.platform
    print sys.long_info

if __name__ == &apos;__main__&apos;:
    m = multiprocessing.Process(target=fun,args=(1,))
    m.start()</code></pre><p>运行结果：</p>
<pre><code>[&apos;E:\\python27\\python study&apos;, &apos;E:\\python27&apos;, &apos;C:\\windows\\SYSTEM32\\python27.zip&apos;, &apos;F:\\Python27\\DLLs&apos;, &apos;F:\\Python27\\lib&apos;, &apos;F:\\Python27\\lib\\plat-win&apos;, &apos;F:\\Python27\\lib\\lib-tk&apos;, &apos;F:\\Python27&apos;, &apos;F:\\Python27\\lib\\site-packages&apos;, &apos;F:\\Python27\\lib\\site-packages\\certifi-2017.7.27.1-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\idna-2.6-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\pypiwin32-219-py2.7-win-amd64.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\future-0.16.0-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\dis3-0.1.1-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\macholib-1.8-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\pefile-2017.9.3-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\altgraph-0.14-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\beautifulsoup4-4.6.0-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\chardet-3.0.4-py2.7.egg&apos;]
sys.version_info(major=2, minor=7, micro=14, releaselevel=&apos;final&apos;, serial=0)
win32
sys.long_info(bits_per_digit=30, sizeof_digit=4)</code></pre><h1 id="案例二-数据通信"><a href="#案例二-数据通信" class="headerlink" title="案例二 数据通信"></a>案例二 数据通信</h1><p>ipc：就是进程间的通信模式，常用的一半是socke，rpc，pipe和消息队列等。</p>
<p>multiprocessing提供了threading包中没有的IPC(比如Pipe和Queue)，效率上更高。应优先考虑Pipe和Queue，避免使用Lock/Event/Semaphore/Condition等同步方式 (因为它们占据的不是用户进程的资源)。</p>
<h2 id="使用Array共享数据"><a href="#使用Array共享数据" class="headerlink" title="使用Array共享数据"></a>使用Array共享数据</h2><p>对于Array数组类，括号内的“i”表示它内部的元素全部是int类型，而不是指字符“i”，数组内的元素可以预先指定，也可以只指定数组的长度。Array类在实例化的时候必须指定数组的数据类型和数组的大小，类似temp = Array(‘i’, 5)。对于数据类型有下面的对应关系：</p>
<pre><code>&apos;c&apos;: ctypes.c_char, &apos;u&apos;: ctypes.c_wchar,
&apos;b&apos;: ctypes.c_byte, &apos;B&apos;: ctypes.c_ubyte,
&apos;h&apos;: ctypes.c_short, &apos;H&apos;: ctypes.c_ushort,
&apos;i&apos;: ctypes.c_int, &apos;I&apos;: ctypes.c_uint,
&apos;l&apos;: ctypes.c_long, &apos;L&apos;: ctypes.c_ulong,
&apos;f&apos;: ctypes.c_float, &apos;d&apos;: ctypes.c_double</code></pre><p>代码实例：</p>
<pre><code>from multiprocessing import Process
from multiprocessing import Array

def func(i,temp):
    temp[0] += 100
    print(&quot;进程%s &quot; % i, &apos; 修改数组第一个元素后-----&gt;&apos;, temp[0])

if __name__ == &apos;__main__&apos;:
    temp = Array(&apos;i&apos;, [1, 2, 3, 4])
    for i in range(10):
        p = Process(target=func, args=(i, temp))
        p.start()</code></pre><p>运行结果：</p>
<pre><code>进程2   修改数组第一个元素后-----&gt; 101
进程4   修改数组第一个元素后-----&gt; 201
进程5   修改数组第一个元素后-----&gt; 301
进程3   修改数组第一个元素后-----&gt; 401
进程1   修改数组第一个元素后-----&gt; 501
进程6   修改数组第一个元素后-----&gt; 601
进程9   修改数组第一个元素后-----&gt; 701
进程8   修改数组第一个元素后-----&gt; 801
进程0   修改数组第一个元素后-----&gt; 901
进程7   修改数组第一个元素后-----&gt; 1001</code></pre><h2 id="使用Manager共享数据"><a href="#使用Manager共享数据" class="headerlink" title="使用Manager共享数据"></a>使用Manager共享数据</h2><p>通过Manager类也可以实现进程间数据的共享，主要用于线程池之间通信，Manager()返回的manager对象提供一个服务进程，使得其他进程可以通过代理的方式操作Python对象。manager对象支持 list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value ,Array等多种格式。</p>
<p>代码实例：</p>
<pre><code>from multiprocessing import Process
from multiprocessing import Manager

def func(i, dic):
    dic[&quot;num&quot;] = 100+i
    print(dic.items())

if __name__ == &apos;__main__&apos;:
    dic = Manager().dict()
    for i in range(10):
        p = Process(target=func, args=(i, dic))
        p.start()
        p.join()</code></pre><h2 id="使用queues的Queue类共享数据"><a href="#使用queues的Queue类共享数据" class="headerlink" title="使用queues的Queue类共享数据"></a>使用queues的Queue类共享数据</h2><p>multiprocessing是一个包，它内部有一个queues模块，提供了一个Queue队列类，可以实现进程间的数据共享，如下例所示：</p>
<pre><code>import multiprocessing
from multiprocessing import Process
from multiprocessing import queues

def func(i, q):
    ret = q.get()
    print(&quot;进程%s从队列里获取了一个%s，然后又向队列里放入了一个%s&quot; % (i, ret, i))
    q.put(i)

if __name__ == &quot;__main__&quot;:
    lis = queues.Queue(20, ctx=multiprocessing)
    lis.put(0)
    for i in range(10):
        p = Process(target=func, args=(i, lis,))
        p.start()</code></pre><p>运行结果：</p>
<pre><code>进程1从队列里获取了一个0，然后又向队列里放入了一个1
进程4从队列里获取了一个1，然后又向队列里放入了一个4
进程2从队列里获取了一个4，然后又向队列里放入了一个2
进程6从队列里获取了一个2，然后又向队列里放入了一个6
进程0从队列里获取了一个6，然后又向队列里放入了一个0
进程5从队列里获取了一个0，然后又向队列里放入了一个5
进程9从队列里获取了一个5，然后又向队列里放入了一个9
进程7从队列里获取了一个9，然后又向队列里放入了一个7
进程3从队列里获取了一个7，然后又向队列里放入了一个3
进程8从队列里获取了一个3，然后又向队列里放入了一个8</code></pre><p>例如来跑多进程对一批IP列表进行运算，运算后的结果都存到Queue队列里面，这个就必须使用multiprocessing提供的Queue来实现</p>
<p>关于queue和Queue，在Python库中非常频繁的出现，很容易就搞混淆了。甚至是multiprocessing自己还有一个Queue类(大写的Q)和的Manager类中提供的Queue方法，一样能实现消息队列queues.Queue的功能，导入方式是from multiprocessing import Queue，前者Queue用于多个进程间通信，和queues.Queue()差不多，后者Manager().queue用于进程池之间通信。</p>
<h2 id="使用pipe实现进程间通信"><a href="#使用pipe实现进程间通信" class="headerlink" title="使用pipe实现进程间通信"></a>使用pipe实现进程间通信</h2><p>pipe只能适用于两个进程间通信，queue则没这个限制，他有两个方法</p>
<pre><code>receive_pi = Pipe()
# 定义变量，用来获取数据
send_pi = Pipe()
# 用来发送数据</code></pre><p>具体例子如下：</p>
<pre><code>from multiprocessing import Pipe,Process
import time
def produce(pipe):
    pipe.send(&apos;666&apos;)
    time.sleep(1)
def consumer(pipe):
    print(pipe.recv())
    # 有些类似socket的recv方法
if __name__ == &apos;__main__&apos;:
    send_pi,recv_pi = Pipe()
    my_pro = Process(target=produce,args=(send_pi,))
    my_con = Process(target=consumer,args=(recv_pi,))
    my_pro.start()
    my_con.start()
    my_pro.join()
    my_con.join()</code></pre><p>pipe相当于queue的一个子集，只能服务两个进程，pipe的性能高于queue。</p>
<h1 id="案例三-进程锁"><a href="#案例三-进程锁" class="headerlink" title="案例三 进程锁"></a>案例三 进程锁</h1><p>一般来说每个进程使用单独的空间，不必加进程锁的，但是如果你需要先实现进程数据共享，<strong>使用案例二中的代码</strong>，又害怕造成数据抢夺和脏数据的问题。就可以设置进程锁，与threading类似，在multiprocessing里也有同名的锁类RLock，Lock，Event，Condition和 Semaphore，连用法都是一样样的。</p>
<p><strong>如果有多个进程要上锁，使用multiprocessing.Manager().BoundedSemaphore(1)</strong></p>
<p>代码实例：</p>
<pre><code>from multiprocessing import Process
from multiprocessing import Array
from multiprocessing import RLock, Lock, Event, Condition, Semaphore
import time

def func(i,lis,lc):
    lc.acquire()
    lis[0] = lis[0] - 1
    time.sleep(1)
    print(&apos;say hi&apos;, lis[0])
    lc.release()

if __name__ == &quot;__main__&quot;:
    array = Array(&apos;i&apos;, 1)
    array[0] = 10
    lock = RLock()
    for i in range(10):
        p = Process(target=func, args=(i, array, lock))
        p.start()</code></pre><p>运行结果：</p>
<pre><code>say hi 9
say hi 8
say hi 7
say hi 6
say hi 5
say hi 4
say hi 3
say hi 2
say hi 1
say hi 0</code></pre><h1 id="案例四-进程池"><a href="#案例四-进程池" class="headerlink" title="案例四 进程池"></a>案例四 进程池</h1><p>from multiprocessing import Pool导入就行，非常容易使用的。进程池内部维护了一个进程序列，需要时就去进程池中拿取一个进程，如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。</p>
<ol>
<li>apply() 同步执行（串行）</li>
<li>apply_async() 异步执行（并行）</li>
<li>terminate() 立刻关闭进程池</li>
<li>join() 主进程等待所有子进程执行完毕。必须在close或terminate()之后。</li>
<li>close() 等待所有进程结束后，才关闭进程池。</li>
</ol>
<p>代码实例：</p>
<pre><code>from multiprocessing import Pool
import time
def func(args):
    time.sleep(1)
    print(&quot;正在执行进程 &quot;, args)
if __name__ == &apos;__main__&apos;:
    p = Pool(5)     # 创建一个包含5个进程的进程池
    for i in range(30):
        # 有30个任务
        p.apply_async(func=func, args=(i,))
        # 异步执行，并发。这里不用target，要用func
    p.close()           # 等子进程执行完毕后关闭进程池
    # time.sleep(2)
    # p.terminate()     # 立刻关闭进程池
    p.join()</code></pre><p>from multiprocessing.dummy import Pool as ThreadPool 是多线程进程池，绑定一个cpu核心。from multiprocessing import Pool多进程，运行于多个cpu核心。multiprocessing 是多进程模块， 而multiprocessing.dummy是以相同API实现的多线程模块。<br>没有绕过GIL情况下，多线程一定受GIL限制。</p>
<p>代码实例：</p>
<pre><code>from multiprocessing.dummy import Pool as tp
def fun(i):
    print i+i+i+i

list_i=[range(100)]

px = tp(processes=8)
# 开启8个线程池
px.map(fun,list_i)
px.close()
px.join()</code></pre><p>使用dummy方法可以不用__name__=’__main__‘，并且用法很简单，开启线程池用法一样，需要注意的是导入的参数，要在一个列表中导入。比如你有一批数据要放进这个线程池，就直接把这批数据放在一个列表中。</p>
<h1 id="案例五-爬虫进程池"><a href="#案例五-爬虫进程池" class="headerlink" title="案例五 爬虫进程池"></a>案例五 爬虫进程池</h1><p>案例来自<a href="https://morvanzhou.github.io/tutorials/data-manipulation/scraping/4-01-distributed-scraping/" target="_blank" rel="noopener">莫凡</a></p>
<h2 id="什么是分布式爬虫"><a href="#什么是分布式爬虫" class="headerlink" title="什么是分布式爬虫"></a>什么是分布式爬虫</h2><p>分布式爬虫主要是为了非常有效率的抓取网页, 我们的程序一般是单线程跑的, 指令也是一条条处理的, 每执行完一条指令才能跳到下一条. 那么在爬虫的世界里, 这里存在着一个问题.</p>
<p>如果你已经顺利地执行过了前几节的爬虫代码, 你会发现, 有时候代码运行的时间大部分都花在了下载网页上. 有时候不到一秒能下载好一张网页的 HTML, 有时候却要几十秒. 而且非要等到 HTML 下载好了以后, 才能执行网页分析等步骤. 这非常浪费时间.</p>
<p>如果我们能合理利用计算资源, 在下载一部分网页的时候就已经开始分析另一部分网页了. 这将会大大节省整个程序的运行时间. 又或者, 我们能同时下载多个网页, 同时分析多个网页, 这样就有种事倍功半的效用. 分布式爬虫的体系有很多种, 处理优化的问题也是多样的. 这里有一篇博客可以当做扩展阅读, 来了解当今比较流行的分布式爬虫框架.</p>
<h2 id="我们的分布式爬虫"><a href="#我们的分布式爬虫" class="headerlink" title="我们的分布式爬虫"></a>我们的分布式爬虫</h2><p>而今天我们想搭建的这一个爬虫, 就是同时下载, 同时分析的这一种类型的分布式爬虫. 虽然算不上特别优化的框架, 但是概念理解起来比较容易. 我有尝试过徒手写高级一点的分布式爬虫, 但是写起来非常麻烦. 我琢磨了一下, 打算给大家介绍的这种分布式爬虫代码也较好写, 而且效率比普通爬虫快了3.5倍. 我也特地画了张图给大家解释一下要搭建的分布式爬虫.</p>
<p><img src="https://morvanzhou.github.io/static/results/scraping/4-1-1.png" alt=""></p>
<p>主要来说, 我们最开始有一个网页, 比如说是莫烦Python的首页, 然后首页中有很多 url, 我们使用多进程 (Python多进程教程) 同时开始下载这些 url, 得到这些 url 的 HTML 以后, 同时开始解析 (比如 BeautifulSoup) 网页内容. 在网页中寻找这个网站还没有爬过的链接. 最终爬完整个 莫烦 Python 网站所有页面.</p>
<p>有了这种思路, 我们就可以开始写代码了. 你可以在我的 Github 一次性观看全部代码.</p>
<p>首先 import 全部要用的模块, 并规定一个主页. 注意, 我用这份代码测试我内网的网站(速度不受外网影响) 所以使用的 base_url 是 “<a href="http://127.0.0.1:4000/”" target="_blank" rel="noopener">http://127.0.0.1:4000/”</a>, 如果你要爬 莫烦Python, 你的 base_url 要是 “<a href="https://morvanzhou.github.io/”" target="_blank" rel="noopener">https://morvanzhou.github.io/”</a> (下载速度会受外网影响).</p>
<pre><code>import multiprocessing as mp
import time
from urllib.request import urlopen, urljoin
from bs4 import BeautifulSoup
import re

# base_url = &quot;http://127.0.0.1:4000/&quot;
base_url = &apos;https://morvanzhou.github.io/&apos;</code></pre><p>我们定义两个功能, 一个是用来爬取网页的(crawl), 一个是解析网页的(parse). 有了前几节内容的铺垫, 你应该能一言看懂下面的代码. crawl() 用 urlopen 来打开网页, 我用的内网测试, 所以为了体现下载网页的延迟, 添加了一个 time.sleep(0.1) 的下载延迟. 返回原始的 HTML 页面, parse() 就是在这个 HTML 页面中找到需要的信息, 我们用 BeautifulSoup 找 (BeautifulSoup 教程). 返回找到的信息.</p>
<pre><code>def crawl(url):
    response = urlopen(url)
    # time.sleep(0.1)             # slightly delay for downloading
    return response.read().decode()


def parse(html):
    soup = BeautifulSoup(html, &apos;lxml&apos;)
    urls = soup.find_all(&apos;a&apos;, {&quot;href&quot;: re.compile(&apos;^/.+?/$&apos;)})
    title = soup.find(&apos;h1&apos;).get_text().strip()
    page_urls = set([urljoin(base_url, url[&apos;href&apos;]) for url in urls])   # 去重
    url = soup.find(&apos;meta&apos;, {&apos;property&apos;: &quot;og:url&quot;})[&apos;content&apos;]
    return title, page_urls, url</code></pre><p>网页中爬取中, 肯定会爬到重复的网址, 为了去除掉这些重复, 我们使用 python 的 set 功能. 定义两个 set, 用来搜集爬过的网页和没爬过的.</p>
<pre><code>unseen = set([base_url,])
seen = set()</code></pre><h2 id="测试普通爬法"><a href="#测试普通爬法" class="headerlink" title="测试普通爬法"></a>测试普通爬法</h2><p>为了对比效果, 我们将在下面对比普通的爬虫和这种分布式的效果. 如果是普通爬虫, 我简化了一下接下来的代码, 将一些不影响的代码去除掉了, 如果你想看全部的代码, 请来到我的 Github. 我们用循环一个个 crawl unseen 里面的 url, 爬出来的 HTML 放到 parse 里面去分析得到结果. 接着就是更新 seen 和 unseen 这两个集合了.</p>
<p>特别注意: 任何网站都是有一个服务器压力的, 如果你爬的过于频繁, 特别是使用多进程爬取或异步爬取, 一次性提交请求给服务器太多次, 这将可能会使得服务器瘫痪, 你可能再也看不到莫烦 Python 了. 所以为了安全起见, 我限制了爬取数量(restricted_crawl=True). 因为我测试使用的是内网 “<a href="http://127.0.0.1:4000/”" target="_blank" rel="noopener">http://127.0.0.1:4000/”</a> 所以不会有这种压力. 你在以后的爬网页中, 会经常遇到这样的爬取次数的限制 (甚至被封号). 我以前爬 github 时就被限制成一小时只能爬60页.</p>
<pre><code># DON&apos;T OVER CRAWL THE WEBSITE OR YOU MAY NEVER VISIT AGAIN
if base_url != &quot;http://127.0.0.1:4000/&quot;:
    restricted_crawl = True
else:
    restricted_crawl = False

while len(unseen) != 0:                 # still get some url to visit
    if restricted_crawl and len(seen) &gt;= 20:
        break
    htmls = [crawl(url) for url in unseen]
    results = [parse(html) for html in htmls]

    seen.update(unseen)         # seen the crawled
    unseen.clear()              # nothing unseen

    for title, page_urls, url in results:
        unseen.update(page_urls - seen)     # get new url to crawl</code></pre><p>使用这种单线程的方法, 在我的内网上面爬, 爬完整个 莫烦Python, 一共消耗 52.3秒. 接着我们把它改成多进程分布式.</p>
<h2 id="测试分布式爬法"><a href="#测试分布式爬法" class="headerlink" title="测试分布式爬法"></a>测试分布式爬法</h2><p>还是上一个 while 循环, 首先我们创建一个进程池(Pool). 不太懂进程池的朋友看过来. 然后我们修改得到 htmls 和 results 的两句代码. 其他都不变, 只将这两个功能给并行了. 我在这里写的都是简化代码, 你可以在这里 看到完整代码.</p>
<pre><code>pool = mp.Pool(4)
while len(unseen) != 0:
    # htmls = [crawl(url) for url in unseen]
    # ---&gt;
    crawl_jobs = [pool.apply_async(crawl, args=(url,)) for url in unseen]
    htmls = [j.get() for j in crawl_jobs]

    # results = [parse(html) for html in htmls]
    # ---&gt;
    parse_jobs = [pool.apply_async(parse, args=(html,)) for html in htmls]
    results = [j.get() for j in parse_jobs]</code></pre><p>还是在内网测试, 只用了 16.3秒!! 这可比上面的单线程爬虫快了3.5倍. 而且我还不是在外网测试的. 如果在外网, 爬取一张网页的时间更长, 使用多进程会更加有效率, 节省的时间更多.</p>
<h1 id="各模块作用"><a href="#各模块作用" class="headerlink" title="各模块作用"></a>各模块作用</h1><h2 id="Process介绍"><a href="#Process介绍" class="headerlink" title="Process介绍"></a>Process介绍</h2><p>构造方法:</p>
<ol>
<li>Process([group [, target [, name [, args [, kwargs]]]]])</li>
<li>group: 线程组，目前还没有实现，库引用中提示必须是None；</li>
<li>target: 要执行的方法；</li>
<li>name: 进程名；</li>
<li>args/kwargs: 要传入方法的参数。</li>
</ol>
<p>实例方法:</p>
<ol>
<li>is_alive()：返回进程是否在运行。</li>
<li>join([timeout])：阻塞当前上下文环境的进程程，直到调用此方法的进程终止或到达指定的3. timeout（可选参数）。</li>
<li>start()：进程准备就绪，等待CPU调度。</li>
<li>run()：strat()调用run方法，如果实例进程时未制定传入target，这star执行t默认run()方法。</li>
<li>terminate()：不管任务是否完成，立即停止工作进程。</li>
</ol>
<p>属性：</p>
<ol>
<li>authkey</li>
<li>daemon：和线程的setDeamon功能一样（将父进程设置为守护进程，当父进程结束时，子进程也结束）。</li>
<li>exitcode(进程在运行时为None、如果为–N，表示被信号N结束）。</li>
<li>name：进程名字。</li>
<li>pid：进程号。</li>
</ol>
<h2 id="Pool介绍"><a href="#Pool介绍" class="headerlink" title="Pool介绍"></a>Pool介绍</h2><p>Multiprocessing.Pool可以提供指定数量的进程供用户调用，当有新的请求提交到pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行它。在共享资源时，只能使用Multiprocessing.Manager类，而不能使用Queue或者Array。Pool类用于需要执行的目标很多，而手动限制进程数量又太繁琐时，如果目标少且不用控制进程数量则可以用Process类。</p>
<p>构造方法：</p>
<ol>
<li>Pool([processes[, initializer[, initargs[, maxtasksperchild[, context]]]]])</li>
<li>processes ：使用的工作进程的数量，如果processes是None那么使用 os.cpu_count()返回的数量。</li>
<li>initializer： 如果initializer是None，那么每一个工作进程在开始的时候会调用initializer(*initargs)。</li>
<li>maxtasksperchild：工作进程退出之前可以完成的任务数，完成后用一个新的工作进程来替代原进程，来让闲置的资源被释放。maxtasksperchild默认是None，意味着只要Pool存在工作进程就会一直存活。</li>
<li>context: 用在制定工作进程启动时的上下文，一般使用 multiprocessing.Pool() 或者一个context对象的Pool()方法来创建一个池，两种方法都适当的设置了context。</li>
</ol>
<p>实例方法：</p>
<ol>
<li>apply_async(func[, args[, kwds[, callback]]]) 它是非阻塞。</li>
<li>apply(func[, args[, kwds]])是阻塞的</li>
<li>close() 关闭pool，使其不在接受新的任务。</li>
<li>terminate() 关闭pool，结束工作进程，不在处理未完成的任务。</li>
<li>join() 主进程阻塞，等待子进程的退出， join方法要在close或terminate之后使用。</li>
</ol>
<p>Pool使用方法</p>
<p>Pool+map函数</p>
<p>说明：此写法缺点在于只能通过map向函数传递一个参数。</p>
<pre><code>from multiprocessing import Pool
def test(i):
    print i
if __name__==&quot;__main__&quot;:
    lists=[1,2,3]
    pool=Pool(processes=2) #定义最大的进程数
    pool.map(test,lists)        #p必须是一个可迭代变量。
    pool.close()
    pool.join()</code></pre><p>异步进程池（非阻塞）</p>
<pre><code>from multiprocessing import Pool
def test(i):
    print i
if __name__==&quot;__main__&quot;:
    pool = Pool(processes=10)
    for i  in xrange(500):
        &apos;&apos;&apos;
        For循环中执行步骤：
        （1）循环遍历，将500个子进程添加到进程池（相对父进程会阻塞）
        （2）每次执行10个子进程，等一个子进程执行完后，立马启动新的子进程。（相对父进程不阻塞）

        apply_async为异步进程池写法。
        异步指的是启动子进程的过程，与父进程本身的执行（print）是异步的，而For循环中往进程池添加子进程的过程，与父进程本身的执行却是同步的。
        &apos;&apos;&apos;
        pool.apply_async(test, args=(i,)) #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.       
    print “test”
    pool.close()
    pool.join()</code></pre><p>执行顺序：For循环内执行了2个步骤，第一步：将500个对象放入进程池（阻塞）。第二步：同时执行10个子进程（非阻塞），有结束的就立即添加，维持10个子进程运行。（apply_async方法的会在执行完for循环的添加步骤后，直接执行后面的print语句，而apply方法会等所有进程池中的子进程运行完以后再执行后面的print语句）</p>
<p>注意：调用join之前，先调用close或者terminate方法，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束。</p>
<p>同步进程池（阻塞）</p>
<pre><code>from multiprocessing import Pool
def test(p):
       print p
       time.sleep(3)
if __name__==&quot;__main__&quot;:
    pool = Pool(processes=10)
    for i  in xrange(500):
    &apos;&apos;&apos;
    实际测试发现，for循环内部执行步骤：
    （1）遍历500个可迭代对象，往进程池放一个子进程
    （2）执行这个子进程，等子进程执行完毕，再往进程池放一个子进程，再执行。（同时只执行一个子进程）
    for循环执行完毕，再执行print函数。
    &apos;&apos;&apos;
        pool.apply(test, args=(i,))   #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.
    print “test”
    pool.close()
    pool.join()</code></pre><p>说明：for循环内执行的步骤顺序，往进程池中添加一个子进程，执行子进程，等待执行完毕再添加一个子进程…..等500个子进程都执行完了，再执行print “test”。（从结果来看，并没有多进程并发）</p>
<h2 id="子进程返回值"><a href="#子进程返回值" class="headerlink" title="子进程返回值"></a>子进程返回值</h2><p>在实际使用多进程的时候，可能需要获取到子进程运行的返回值。如果只是用来存储，则可以将返回值保存到一个数据结构中；如果需要判断此返回值，从而决定是否继续执行所有子进程，则会相对比较复杂。另外在Multiprocessing中，可以利用Process与Pool创建子进程，这两种用法在获取子进程返回值上的写法上也不相同。这篇中，我们直接上代码，分析多进程中获取子进程返回值的不同用法，以及优缺点。</p>
<p>初级用法（Pool）</p>
<p>目的：存储子进程返回值</p>
<p>说明：如果只是单纯的存储子进程返回值，则可以使用Pool的apply_async异步进程池；当然也可以使用Process，用法与threading中的相同，这里只介绍前者。</p>
<p>实例：当进程池中所有子进程执行完毕后，输出每个子进程的返回值。</p>
<pre><code>from multiprocessing import Pool
def test(p):     
    return p
if __name__==&quot;__main__&quot;:
    pool = Pool(processes=10)
    result=[]
    for i  in xrange(50000):
       &apos;&apos;&apos;
       for循环执行流程：
       （1）添加子进程到pool，并将这个对象（子进程）添加到result这个列表中。（此时子进程并没有运行）
       （2）执行子进程（同时执行10个）
       &apos;&apos;&apos;
       result.append(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程.       
    pool.join()
    &apos;&apos;&apos;
    遍历result列表，取出子进程对象，访问get()方法，获取返回值。（此时所有子进程已执行完毕）
    &apos;&apos;&apos;
    for i in result:
        print i.get()</code></pre><p>错误写法：</p>
<pre><code>for i  in xrange(50000):
   t=pool.apply_async(test, args=(i,)))
   print t.get()</code></pre><p>说明：这样会造成阻塞，因为get()方法只能等子进程运行完毕后才能调用成功，否则会一直阻塞等待。如果写在for循环内容，相当于变成了同步，执行效率将会非常低。</p>
<p>高级用法（Pool）<br>目的：父进程实时获取子进程返回值，以此为标记结束所有进程。</p>
<p>实例（一）<br>执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。</p>
<pre><code>from multiprocessing import Pool
import Queue
import time
def test(p):
    time.sleep(0.001)
    if p==10000:
        return True
    else:
        return False
if __name__==&quot;__main__&quot;:
    pool = Pool(processes=10)
    q=Queue.Queue()
    for i  in xrange(50000):
        &apos;&apos;&apos;
        将子进程对象存入队列中。
        &apos;&apos;&apos;
        q.put(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程.       
    &apos;&apos;&apos;
    因为这里使用的为pool.apply_async异步方法，因此子进程执行的过程中，父进程会执行while，获取返回值并校验。
    &apos;&apos;&apos;
    while 1:
        if q.get().get():
            pool.terminate() #结束进程池中的所有子进程。
            break
    pool.join()</code></pre><p>说明：总共要执行50000个子进程（并发数量为10），当其中一个子进程返回True时，结束进程池。因为使用了apply_async为异步进程，因此在执行完for循环的添加子进程操作后（只是添加并没有执行完所有的子进程），可以直接执行while代码，实时判断子进程返回值是否有True，有的话结束所有进程。</p>
<p>优点：不必等到所有子进程结束再结束程序，只要得到想要的结果就可以提前结束，节省资源。</p>
<p>不足：当需要执行的子进程非常大时，不适用，因为for循环在添加子进程时，要花费很长的时间，虽然是异步，但是也需要等待for循环添加子进程操作结束才能执行while代码，因此会比较慢。</p>
<p>实例（二）</p>
<p>多线程+多进程，添加执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。</p>
<pre><code>from multiprocessing import Pool
import Queue
import threading
import time
def test(p):
    time.sleep(0.001)
    if p==10000:
        return True
    else:
        return False
if __name__==&quot;__main__&quot;:
    result=Queue.Queue() #队列
    pool = Pool()
    def pool_th():
        for i  in xrange(50000000): ##这里需要创建执行的子进程非常多
            try:
                result.put(pool.apply_async(test, args=(i,)))
            except:
                break
    def result_th():
        while 1:
            a=result.get().get() #获取子进程返回值
            if a:
                pool.terminate() #结束所有子进程
                break
    &apos;&apos;&apos;
    利用多线程，同时运行Pool函数创建执行子进程，以及运行获取子进程返回值函数。
    &apos;&apos;&apos;
    t1=threading.Thread(target=pool_th)
    t2=threading.Thread(target=result_th)
    t1.start()
    t2.start()
    t1.join()
    t2.join()
    pool.join()</code></pre><p>执行流程：利用多线程，创建一个执行pool_th函数线程，一个执行result_th函数线程，pool_th函数用来添加进程池，开启进程执行功能函数并将子进程对象存入队列，而result_th()函数用来不停地从队列中取子进程对象，调用get（）方法获取返回值。等发现其中存在子进程的返回值为True时，结束所有进程，最后结束线程。</p>
<p>优点：弥补了实例（一）的不足，即使for循环的子进程数量很多，也能提高性能，因为for循环与判断子进程返回值同时进行。</p>
<p><a href="https://thief.one/2016/11/23/Python-multiprocessing/" target="_blank" rel="noopener">参考链接</a></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Sxadmin</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://sxadmin.github.io/2018/04/30/Python%20multiprocess%20%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9D%97/">https://sxadmin.github.io/2018/04/30/Python%20multiprocess%20%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9D%97/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://sxadmin.github.io" target="_blank">Sxadmin blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/">多线程</a></div><div class="post_share"><div class="social-share" data-image="/img/cover/cover9.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="post-qr-code__img" src="/img/wechat.jpg" alt="微信"/><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="post-qr-code__img" src="/img/alipay.jpg" alt="支付寶"/><div class="post-qr-code__desc">支付寶</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2018/05/04/Python%20collections%20%E6%A8%A1%E5%9D%97/"><img class="prev_cover" src="/img/cover/cover11.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python collections 模块</div></div></a></div><div class="next-post pull_right"><a href="/2018/04/30/Python%20threading%20%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9D%97/"><img class="next_cover" src="/img/cover/cover100.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Python threading 多线程模块</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2018/04/30/Python threading 多线程模块/" title="Python threading 多线程模块"><img class="relatedPosts_cover" src="/img/cover/cover100.png"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2018-04-30</div><div class="relatedPosts_title">Python threading 多线程模块</div></div></a></div></div><div class="clear_both"></div></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Sxadmin</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@3/instantpage.min.js" type="module"></script></body></html>